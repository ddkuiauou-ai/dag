from dagster_docker import PipesDockerClient
import dagster as dg
import docker
import re
import json


def clean_ansi_codes(text: str) -> str:
    """ANSI ì»¬ëŸ¬ ì½”ë“œë¥¼ ì œê±°í•˜ì—¬ ê¹”ë”í•œ ë¡œê·¸ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
    ansi_escape = re.compile(r'\x1B(?:[@-Z\\-_]|\[[0-?]*[ -/]*[@-~])')
    return ansi_escape.sub('', text)


def extract_crawl_stats(log_text: str) -> dict:
    """í¬ë¡¤ë§ í†µê³„ ì •ë³´ë¥¼ ë¡œê·¸ì—ì„œ ì¶”ì¶œ"""
    stats = {"total_requests": 0, "succeeded": 0, "failed": 0}
    
    # "Total X requests: Y succeeded, Z failed" íŒ¨í„´ ë§¤ì¹­
    pattern = r'Total (\d+) requests: (\d+) succeeded, (\d+) failed'
    match = re.search(pattern, log_text)
    
    if match:
        stats["total_requests"] = int(match.group(1))
        stats["succeeded"] = int(match.group(2))
        stats["failed"] = int(match.group(3))
    
    return stats


@dg.asset(
    group_name="CD", 
    kinds={"source"},
    tags={
        "domain": "image_processing",
        "data_tier": "bronze",
        "source": "docker"
    },
    description="CD í”„ë¡œì íŠ¸ - ë„ì»¤ ì»¨í…Œì´ë„ˆ ì‹¤ì‹œê°„ ë¡œê·¸ ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ì´ë¯¸ì§€ ì²˜ë¦¬"
)
def cd_img_r2_docker(
    context: dg.AssetExecutionContext
) -> dg.MaterializeResult:
    """CD ì´ë¯¸ì§€ ì²˜ë¦¬ìš© ë„ì»¤ ì»¨í…Œì´ë„ˆë¥¼ ì‹¤ì‹œê°„ ë¡œê·¸ ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤."""
    
    docker_client = docker.from_env()
    log_count = 0
    container = None
    processed_images = []  # ì²˜ë¦¬ëœ ì´ë¯¸ì§€ ì¶”ì 
    crawl_stats = {"total_requests": 0, "succeeded": 0, "failed": 0}  # í¬ë¡¤ë§ í†µê³„
    
    try:
        context.log.info("ğŸš€ CD ì´ë¯¸ì§€ ì²˜ë¦¬ ì»¨í…Œì´ë„ˆ ì‹œì‘")
        
        # CD ì´ë¯¸ì§€ ì²˜ë¦¬ìš© ë„ì»¤ ì»¨í…Œì´ë„ˆ ì‹¤í–‰
        container = docker_client.containers.run(
            image="cd-naver-crawler:dev",
            detach=True,
            stdout=True,
            stderr=True,
            remove=False,
            mem_limit="4g",
            environment={
                "LOG_LEVEL": "DEBUG",
                "PYTHONUNBUFFERED": "1",
                "CD_PROJECT": "true",
                "IMAGE_PROCESSING": "true",
                "NO_COLOR": "1",  # ì»¬ëŸ¬ ì¶œë ¥ ë¹„í™œì„±í™”
                "FORCE_COLOR": "0",  # ê°•ì œ ì»¬ëŸ¬ ë¹„í™œì„±í™”
                "CRAWLEE_MEMORY_MBYTES": "4096"                
            }
        )
        
        context.log.info(f"ğŸ“¦ CD ì»¨í…Œì´ë„ˆ ì‹œì‘ë¨: {container.short_id}")
        context.log.info("=== ğŸ”„ ì‹¤ì‹œê°„ ì´ë¯¸ì§€ ì²˜ë¦¬ ë¡œê·¸ ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘ ===")
        
        # ì‹¤ì‹œê°„ ë¡œê·¸ ìŠ¤íŠ¸ë¦¬ë°
        for log_line in container.logs(stream=True, follow=True, timestamps=True):
            try:
                log_text = log_line.decode('utf-8').strip()
                if log_text:
                    # ANSI ì»¬ëŸ¬ ì½”ë“œ ì œê±°
                    clean_log = clean_ansi_codes(log_text)
                    
                    # íšŒì‚¬ ë¡œê³  ì €ì¥ ì´ë²¤íŠ¸ íŠ¹ë³„ ì²˜ë¦¬
                    if "Company logo saved:" in clean_log:
                        # íŒŒì¼ëª… ì¶”ì¶œ
                        filename_match = re.search(r'clogo-[a-f0-9-]+\.png', clean_log)
                        if filename_match:
                            filename = filename_match.group()
                            processed_images.append(filename)
                            context.log.info(f"âœ… CD ë¡œê³  ì €ì¥ ì™„ë£Œ: {filename}")
                        else:
                            context.log.info(f"ğŸ“¸ CD ë¡œê³  ì²˜ë¦¬: {clean_log}")
                    
                    # í¬ë¡¤ë§ ì™„ë£Œ í†µê³„ ì¶”ì¶œ
                    elif "PlaywrightCrawler: Finished!" in clean_log and "Total" in clean_log:
                        stats = extract_crawl_stats(clean_log)
                        if stats["total_requests"] > 0:
                            crawl_stats = stats
                            context.log.info(f"ğŸ“ˆ í¬ë¡¤ë§ ì™„ë£Œ í†µê³„: ì´ {stats['total_requests']}ê°œ, ì„±ê³µ {stats['succeeded']}ê°œ, ì‹¤íŒ¨ {stats['failed']}ê°œ")
                        context.log.info(f"ğŸ CD í¬ë¡¤ë§ ì™„ë£Œ: {clean_log}")
                    
                    else:
                        # ì¼ë°˜ ë¡œê·¸ ì¶œë ¥ (ê¹”ë”í•˜ê²Œ ì •ë¦¬ë¨)
                        context.log.info(f"ğŸ“‹ CD_PROCESSOR: {clean_log}")
                    
                    log_count += 1
                    
                    # CD ì´ë¯¸ì§€ ì²˜ë¦¬ëŠ” ìƒëŒ€ì ìœ¼ë¡œ ë¡œê·¸ê°€ ì ì„ ê²ƒìœ¼ë¡œ ì˜ˆìƒ
                    # if log_count > 1500:
                    #     context.log.info("âš ï¸ ë¡œê·¸ ë¼ì¸ 1500ê°œ ì´ˆê³¼ - ìŠ¤íŠ¸ë¦¬ë° ì¤‘ë‹¨")
                    #     break
                        
            except UnicodeDecodeError:
                # ë°”ì´ë„ˆë¦¬ ë°ì´í„°ëŠ” ë¬´ì‹œ
                continue
            except Exception as e:
                context.log.warning(f"ë¡œê·¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                continue
        
        # ì»¨í…Œì´ë„ˆ ì™„ë£Œ ëŒ€ê¸°
        exit_code = container.wait()
        success = exit_code['StatusCode'] == 0
        
        context.log.info(f"=== âœ… CD ì´ë¯¸ì§€ ì²˜ë¦¬ ì™„ë£Œ (exit_code: {exit_code['StatusCode']}) ===")
        
        # ì²˜ë¦¬ëœ ì´ë¯¸ì§€ ìš”ì•½
        if processed_images:
            context.log.info(f"ğŸ“Š ì´ {len(processed_images)}ê°œ íšŒì‚¬ ë¡œê³  ì²˜ë¦¬ ì™„ë£Œ:")
            for img in processed_images:
                context.log.info(f"  ğŸ“¸ {img}")
        
        # ìµœì¢… ë¡œê·¸ í™•ì¸ ë° í†µê³„ ì¶”ì¶œ
        final_logs = container.logs(tail=10).decode('utf-8', errors='ignore')
        if final_logs.strip():
            context.log.info("ğŸ“ CD ì²˜ë¦¬ ìµœì¢… ë¡œê·¸:")
            for line in final_logs.split('\n')[-5:]:
                if line.strip():
                    clean_final = clean_ansi_codes(line)
                    context.log.info(f"ğŸ”š CD_FINAL: {clean_final}")
                    
                    # ìµœì¢… ë¡œê·¸ì—ì„œë„ í†µê³„ ì¶”ì¶œ ì‹œë„ (ë†“ì¹œ ê²½ìš°ë¥¼ ìœ„í•´)
                    if "PlaywrightCrawler: Finished!" in clean_final and crawl_stats["total_requests"] == 0:
                        stats = extract_crawl_stats(clean_final)
                        if stats["total_requests"] > 0:
                            crawl_stats = stats
                            context.log.info(f"ğŸ“ˆ ìµœì¢… í†µê³„ ì¶”ì¶œ: ì´ {stats['total_requests']}ê°œ ì²˜ë¦¬")
        
        # dagster/row_countì— ì„±ê³µí•œ ìš”ì²­ ìˆ˜ ë˜ëŠ” ì²˜ë¦¬ëœ ì´ë¯¸ì§€ ìˆ˜ ì‚¬ìš©
        count_value = max(crawl_stats["succeeded"], len(processed_images))
        
        return dg.MaterializeResult(
            metadata={
                "dagster/row_count": dg.MetadataValue.int(count_value),
                "container_id": dg.MetadataValue.text(container.short_id),
                "exit_code": dg.MetadataValue.int(exit_code['StatusCode']),
                "log_lines_captured": dg.MetadataValue.int(log_count),
                "processed_images_count": dg.MetadataValue.int(len(processed_images)),
                "processed_images": dg.MetadataValue.json(processed_images),
                "crawl_total_requests": dg.MetadataValue.int(crawl_stats["total_requests"]),
                "crawl_succeeded": dg.MetadataValue.int(crawl_stats["succeeded"]),
                "crawl_failed": dg.MetadataValue.int(crawl_stats["failed"]),
                "success": dg.MetadataValue.bool(success),
                "container_image": dg.MetadataValue.text("crawlee-naver-crawler"),
                "processing_timestamp": dg.MetadataValue.text(context.run.run_id),
                "project": dg.MetadataValue.text("CD")
            }
        )
        
    except Exception as e:
        context.log.error(f"âŒ CD ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        raise
    finally:
        # ì»¨í…Œì´ë„ˆ ì •ë¦¬
        if container:
            try:
                container.stop()
                container.remove()
                context.log.info("ğŸ§¹ CD ì»¨í…Œì´ë„ˆ ì •ë¦¬ ì™„ë£Œ")
            except Exception as e:
                context.log.warning(f"CD ì»¨í…Œì´ë„ˆ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
        
        try:
            docker_client.close()
        except:
            pass
