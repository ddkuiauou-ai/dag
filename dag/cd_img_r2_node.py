import dagster as dg
import re
import json
import subprocess
import os # Ensure os is imported if not already for script_env
from datetime import datetime


def clean_ansi_codes(text: str) -> str:
    """ANSI ì»¬ëŸ¬ ì½”ë“œë¥¼ ì œê±°í•˜ì—¬ ê¹”ë”í•œ ë¡œê·¸ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
    ansi_escape = re.compile(r'\x1B(?:[@-Z\\-_]|\[[0-?]*[ -/]*[@-~])')
    return ansi_escape.sub('', text)


def extract_crawl_stats(log_text: str) -> dict:
    """í¬ë¡¤ë§ í†µê³„ ì •ë³´ë¥¼ ë¡œê·¸ì—ì„œ ì¶”ì¶œ"""
    stats = {"total_requests": 0, "succeeded": 0, "failed": 0}
    
    # "Total X requests: Y succeeded, Z failed" íŒ¨í„´ ë§¤ì¹­
    pattern = r'Total (\d+) requests: (\d+) succeeded, (\d+) failed'
    match = re.search(pattern, log_text)
    
    if match:
        stats["total_requests"] = int(match.group(1))
        stats["succeeded"] = int(match.group(2))
        stats["failed"] = int(match.group(3))
    
    return stats


@dg.asset(
    group_name="CD", 
    kinds={"source"},
    tags={
        "domain": "image_processing",
        "data_tier": "bronze",
        "source": "node_script"  # Changed from "docker"
    },
    description="CD í”„ë¡œì íŠ¸ - Node.js ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì§ì ‘ ì‹¤í–‰í•˜ì—¬ ì´ë¯¸ì§€ ì²˜ë¦¬" # Updated description
)
def cd_img_r2_node(
    context: dg.AssetExecutionContext
) -> dg.MaterializeResult:
    """CD ì´ë¯¸ì§€ ì²˜ë¦¬ìš© Node.js ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì§ì ‘ ì‹¤í–‰í•˜ê³  ë¡œê·¸ë¥¼ ìŠ¤íŠ¸ë¦¬ë°í•©ë‹ˆë‹¤."""
    
    context.log.info("ğŸš€ CD ì´ë¯¸ì§€ ì²˜ë¦¬ Node.js ìŠ¤í¬ë¦½íŠ¸ ì‹œì‘ (ìŠ¤íŠ¸ë¦¬ë°)")

    command = ["npx", "tsx", "src/main.ts"]
    cwd = "dag/cd_crawlee/cd-naver-crawler"

    script_env = os.environ.copy()
    script_env.update({
        "LOG_LEVEL": "DEBUG",
        "CD_PROJECT": "true",
        "IMAGE_PROCESSING": "true",
        "NO_COLOR": "1",
        "FORCE_COLOR": "0",
        "CRAWLEE_MEMORY_MBYTES": "4096",
    })

    log_count_stdout = 0
    log_count_stderr = 0
    processed_images = []
    crawl_stats = {"total_requests": 0, "succeeded": 0, "failed": 0}
    full_stdout_log = []
    full_stderr_log = [] # To capture full stderr for error reporting
    process = None

    try:
        context.log.info(f"Executing Node.js script: {' '.join(command)} in {cwd}")
        
        process = subprocess.Popen(
            command,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True,
            env=script_env,
            cwd=cwd,
            bufsize=1 # Line-buffered
        )

        context.log.info("--- Node.js ìŠ¤í¬ë¦½íŠ¸ STDOUT ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘ ---")
        if process.stdout:
            for line in iter(process.stdout.readline, ''):
                cleaned_line = line.strip()
                context.log.info(cleaned_line)
                log_count_stdout += 1
                # ANSI ì½”ë“œëŠ” Dagster UI/CLIì—ì„œ ì§ì ‘ ì²˜ë¦¬ë  ìˆ˜ ìˆìœ¼ë¯€ë¡œ, 
                # clean_ansi_codesëŠ” í†µê³„ ì¶”ì¶œ ì‹œì ì—ë§Œ ì ìš©í•˜ê±°ë‚˜ í•„ìš”ì‹œ ì—¬ê¸°ì„œë„ ì ìš©
                full_stdout_log.append(cleaned_line) 
                
                # íšŒì‚¬ ë¡œê³  ì €ì¥ ì´ë²¤íŠ¸ íŠ¹ë³„ ì²˜ë¦¬
                # clean_ansi_codesë¥¼ ì ìš©í•œ í›„ ë¹„êµí•˜ëŠ” ê²ƒì´ ë” ì•ˆì „í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
                # ì—¬ê¸°ì„œëŠ” ì›ë³¸ ë¡œê·¸ ë¼ì¸ì—ì„œ ì§ì ‘ í™•ì¸í•©ë‹ˆë‹¤.
                if "Company logo saved:" in cleaned_line: # Use cleaned_line for pattern matching
                    filename_match = re.search(r'clogo-[a-f0-9-]+\.png', cleaned_line)
                    if filename_match:
                        filename = filename_match.group()
                        processed_images.append(filename)
                        context.log.info(f"âœ… CD ë¡œê³  ì €ì¥ ì™„ë£Œ (from stream): {filename}")
            process.stdout.close()
        context.log.info("--- Node.js ìŠ¤í¬ë¦½íŠ¸ STDOUT ìŠ¤íŠ¸ë¦¬ë° ì¢…ë£Œ ---")

        # stderr ìŠ¤íŠ¸ë¦¬ë° (ë¹„ë™ê¸°ì ìœ¼ë¡œ ë°œìƒ ê°€ëŠ¥, stdout í›„ ë˜ëŠ” ë™ì‹œì—)
        # Popen.communicate() ë˜ëŠ” ë³„ë„ ìŠ¤ë ˆë“œê°€ ë” ê²¬ê³ í•  ìˆ˜ ìˆìœ¼ë‚˜, 
        # ì—¬ê¸°ì„œëŠ” stdout ì²˜ë¦¬ í›„ stderrë¥¼ ì½ìŠµë‹ˆë‹¤.
        # ë˜ëŠ”, select ëª¨ë“ˆì„ ì‚¬ìš©í•˜ì—¬ stdout/stderrë¥¼ ë™ì‹œì— í´ë§í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        # ê°„ë‹¨í•˜ê²Œ í•˜ê¸° ìœ„í•´, stdoutì„ ëª¨ë‘ ì½ì€ í›„ stderrë¥¼ ì½ìŠµë‹ˆë‹¤.
        # í•˜ì§€ë§Œ ì´ ë°©ì‹ì€ stderrê°€ stdoutë³´ë‹¤ ë¨¼ì € ë§ì´ ìŒ“ì´ë©´ ë²„í¼ ë¬¸ì œ ìƒê¸¸ ìˆ˜ ìˆìŒ.
        # ë” ê²¬ê³ í•œ ë°©ì‹ì€ select ë˜ëŠ” threading.
        
        # ì„ì‹œ: stderrëŠ” communicateë¡œ í•œ ë²ˆì— ì½ê¸° (ìŠ¤íŠ¸ë¦¬ë° íš¨ê³¼ëŠ” ë–¨ì–´ì§€ë‚˜ ì•ˆì •ì )
        # stdout_data, stderr_data = process.communicate() # stdoutì€ ì´ë¯¸ ìœ„ì—ì„œ ì½ì—ˆìœ¼ë¯€ë¡œ ì´ë ‡ê²Œ í•˜ë©´ ì•ˆë¨
        # return_code = process.returncode

        # stderrë„ ìŠ¤íŠ¸ë¦¬ë° (stdout ì²˜ëŸ¼)
        context.log.info("--- Node.js ìŠ¤í¬ë¦½íŠ¸ STDERR ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘ ---")
        if process.stderr:
            for line in iter(process.stderr.readline, ''):
                cleaned_line = line.strip()
                context.log.error(cleaned_line) # Log as error
                log_count_stderr += 1
                full_stderr_log.append(cleaned_line)
            process.stderr.close()
        context.log.info("--- Node.js ìŠ¤í¬ë¦½íŠ¸ STDERR ìŠ¤íŠ¸ë¦¬ë° ì¢…ë£Œ ---")

        return_code = process.wait() # í”„ë¡œì„¸ìŠ¤ ì™„ë£Œ ëŒ€ê¸° ë° ì¢…ë£Œ ì½”ë“œ ê°€ì ¸ì˜¤ê¸°

        # ì „ì²´ stdout ë¡œê·¸ì—ì„œ í†µê³„ ì¶”ì¶œ
        stdout_full_text = "\n".join(full_stdout_log)
        # clean_ansi_codesë¥¼ ì „ì²´ í…ìŠ¤íŠ¸ì— ì ìš© í›„ í†µê³„ ì¶”ì¶œ
        stats_from_stdout = extract_crawl_stats(clean_ansi_codes(stdout_full_text))
        if stats_from_stdout["total_requests"] > 0:
            crawl_stats = stats_from_stdout
            context.log.info(f"ğŸ“ˆ í¬ë¡¤ë§ í†µê³„ (STDOUT ì „ì²´ ë¶„ì„): ì´ {crawl_stats['total_requests']}ê°œ, ì„±ê³µ {crawl_stats['succeeded']}ê°œ, ì‹¤íŒ¨ {crawl_stats['failed']}ê°œ")
        
        success = return_code == 0
        context.log.info(f"=== âœ… CD ì´ë¯¸ì§€ ì²˜ë¦¬ Node.js ìŠ¤í¬ë¦½íŠ¸ ì™„ë£Œ (exit_code: {return_code}) ==-")

        if not success:
            error_message = f"Node.js script '{' '.join(command)}' failed with exit code {return_code}."
            context.log.error(error_message)
            # full_stderr_log ì‚¬ìš©
            if full_stderr_log:
                context.log.error("--- ì „ì²´ STDERR ë‚´ìš© ---")
                for err_line in full_stderr_log:
                    context.log.error(err_line)
            # ì•„ë‹ˆë©´ ë§ˆì§€ë§‰ N ë¼ì¸ë§Œ
            # context.log.error(f"STDERR (last 500 chars from captured): {('\n'.join(full_stderr_log))[-500:]}")
            raise Exception(error_message)

        # ì²˜ë¦¬ëœ ì´ë¯¸ì§€ ìš”ì•½ (from original logic)
        if processed_images:
            context.log.info(f"ğŸ“Š ì´ {len(processed_images)}ê°œ íšŒì‚¬ ë¡œê³  ì²˜ë¦¬ ì™„ë£Œ:")
            for img in processed_images:
                context.log.info(f"  ğŸ“¸ {img}")
        
        # dagster/row_countì— ì„±ê³µí•œ ìš”ì²­ ìˆ˜ ë˜ëŠ” ì²˜ë¦¬ëœ ì´ë¯¸ì§€ ìˆ˜ ì‚¬ìš© (from original logic)
        count_value = max(crawl_stats.get("succeeded", 0), len(processed_images))
        
        return dg.MaterializeResult(
            metadata={
                "dagster/row_count": dg.MetadataValue.int(count_value),
                "script_path": dg.MetadataValue.text(command[-1]),
                "script_command": dg.MetadataValue.text(" ".join(command)),
                "exit_code": dg.MetadataValue.int(return_code),
                "log_lines_stdout": dg.MetadataValue.int(log_count_stdout),
                "log_lines_stderr": dg.MetadataValue.int(log_count_stderr),
                "processed_images_count": dg.MetadataValue.int(len(processed_images)),
                "processed_images": dg.MetadataValue.json(processed_images),
                "crawl_total_requests": dg.MetadataValue.int(crawl_stats["total_requests"]),
                "crawl_succeeded": dg.MetadataValue.int(crawl_stats["succeeded"]),
                "crawl_failed": dg.MetadataValue.int(crawl_stats["failed"]),
                "success": dg.MetadataValue.bool(success),
                "execution_method": dg.MetadataValue.text("subprocess.Popen_node.js_streaming"),
                "processing_timestamp": dg.MetadataValue.text(datetime.now().isoformat()),
                "project": dg.MetadataValue.text("CD")
            }
        )
        
    except subprocess.TimeoutExpired as te: # Popen.wait()ì— timeout ì„¤ì • ì‹œ í•„ìš”
        context.log.error(f"âŒ CD ì´ë¯¸ì§€ ì²˜ë¦¬ Node.js ìŠ¤í¬ë¦½íŠ¸ ì‹œê°„ ì´ˆê³¼: {te}")
        if process: process.kill()
        # stdout/stderr ë°ì´í„°ê°€ te ê°ì²´ì— ìˆì„ ìˆ˜ ìˆìŒ (Python 3.x+)
        if hasattr(te, 'stdout') and te.stdout:
            context.log.error(f"STDOUT on timeout: {te.stdout.decode(errors='ignore')}")
        if hasattr(te, 'stderr') and te.stderr:
            context.log.error(f"STDERR on timeout: {te.stderr.decode(errors='ignore')}")
        raise
    except FileNotFoundError:
        context.log.error(f"âŒ Node.js ìŠ¤í¬ë¦½íŠ¸ ë˜ëŠ” 'npx'/'tsx' ì‹¤í–‰ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. Command: {' '.join(command)}. PATHì™€ ìŠ¤í¬ë¦½íŠ¸ ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        raise
    except Exception as e:
        context.log.error(f"âŒ CD ì´ë¯¸ì§€ ì²˜ë¦¬ Node.js ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
        # process ê°ì²´ê°€ ìˆê³ , stdout/stderrê°€ ìº¡ì²˜ë˜ì—ˆë‹¤ë©´ ë¡œê·¸ ë‚¨ê¸°ê¸°
        if process and process.stdout and not process.stdout.closed:
            stdout_remains = process.stdout.read()
            if stdout_remains:
                context.log.error(f"Remaining STDOUT: {stdout_remains}")
        if process and process.stderr and not process.stderr.closed:
            stderr_remains = process.stderr.read()
            if stderr_remains:
                context.log.error(f"Remaining STDERR: {stderr_remains}")
        # ë˜ëŠ” full_stdout_log / full_stderr_log ì‚¬ìš©
        if full_stdout_log:
            context.log.error(f"Captured STDOUT so far: {('\n'.join(full_stdout_log))[-1000:]}")
        if full_stderr_log:
            context.log.error(f"Captured STDERR so far: {('\n'.join(full_stderr_log))[-1000:]}")
        raise
    finally:
        if process: # Ensure pipes are closed and process is reaped
            if process.stdout and not process.stdout.closed:
                process.stdout.close()
            if process.stderr and not process.stderr.closed:
                process.stderr.close()
            if process.poll() is None: # If still running, terminate
                try:
                    process.terminate()
                    process.wait(timeout=5) # Give it a chance to terminate gracefully
                except subprocess.TimeoutExpired:
                    process.kill()
                    process.wait()
                except Exception as e_finally:
                    context.log.error(f"Error during process cleanup: {e_finally}")
